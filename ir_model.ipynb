{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa6cdcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Python imports\n",
    "import os\n",
    "import copy\n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Astropy imports\n",
    "from astropy.io import fits\n",
    "from astropy.wcs import WCS\n",
    "from astropy.visualization import ImageNormalize, LogStretch\n",
    "import astropy.io.fits as pyfits\n",
    "\n",
    "# Lenstronomy imports\n",
    "import lenstronomy\n",
    "from lenstronomy.Plots import chain_plot\n",
    "from lenstronomy.Plots.model_plot import ModelPlot\n",
    "from lenstronomy.Data.psf import PSF\n",
    "from lenstronomy.Util import kernel_util\n",
    "from lenstronomy.Data.pixel_grid import PixelGrid\n",
    "from lenstronomy.Workflow.fitting_sequence import FittingSequence\n",
    "from lenstronomy.Util import mask_util, util"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd991c0",
   "metadata": {},
   "source": [
    "## Redirect MCMC output to .txt file to not clutter the notebook later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6020d7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import contextlib\n",
    "\n",
    "@contextlib.contextmanager\n",
    "def suppress_stdout_stderr(to_file):\n",
    "    \"\"\"\n",
    "    Redirect stdout and stderr to a file.\n",
    "    \"\"\"\n",
    "    with open(to_file, 'w') as f:\n",
    "        old_stdout = sys.stdout\n",
    "        old_stderr = sys.stderr\n",
    "        sys.stdout = f\n",
    "        sys.stderr = f\n",
    "        try:\n",
    "            yield\n",
    "        finally:\n",
    "            sys.stdout = old_stdout\n",
    "            sys.stderr = old_stderr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ed5e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load PSF data\n",
    "psf_file = f'cutout_data/{system_name}/{filter}/outputs/full_PSF.fits'\n",
    "\n",
    "kernel = pyfits.getdata(psf_file)\n",
    "psf_type = 'PIXEL'  # 'gaussian', 'pixel', 'NONE'\n",
    "kernel_size = 301\n",
    "\n",
    "variance = np.loadtxt(f'cutout_data/{system_name}/{filter}/psf_variance.txt')\n",
    "\n",
    "var_array = np.array(variance)\n",
    "\n",
    "kernel_cut = kernel_util.cut_psf(kernel, kernel_size)\n",
    "kwargs_psf = {'psf_type': psf_type, 'kernel_point_source': kernel_cut, \n",
    "              'point_source_supersampling_factor': 3, \n",
    "              'psf_variance_map': var_array}\n",
    "psf_class = PSF(**kwargs_psf)\n",
    "\n",
    "kernel_psf_class = psf_class.kernel_point_source\n",
    "\n",
    "plt.matshow(np.log10(kernel_psf_class))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9653aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the FITS file and extract the header\n",
    "filename = f'cutout_data/{system_name}/{filter}/{system_name}_{filter}_cutout.fits'\n",
    "\n",
    "with fits.open(filename) as hdul:\n",
    "    header = hdul[0].header\n",
    "    image_data = hdul[0].data \n",
    "\n",
    "# read out matrix elements and convert them in units of arc seconds\n",
    "CD1_1 = header['CD1_1'] * 3600  # change in arc sec per pixel d(ra)/dx\n",
    "CD1_2 = header['CD1_2'] * 3600\n",
    "CD2_1 = header['CD2_1'] * 3600\n",
    "CD2_2 = header['CD2_2'] * 3600\n",
    "\n",
    "# generate pixel-to-coordinate transform matrix and its inverse\n",
    "pix2coord_transform_undistorted = np.array([[CD1_1, CD1_2], [CD2_1, CD2_2]])\n",
    "det = CD1_1*CD2_2 - CD1_2*CD2_1\n",
    "coord2pix_transform_undistorted = np.array([[CD2_2, -CD1_2], [-CD2_1, CD1_1]])/det\n",
    "\n",
    "# as an example, we set the coordinate zero point in the center of the image and compute \n",
    "# the coordinate at the pixel (0,0) at the edge of the image\n",
    "\n",
    "# read out pixel size of image\n",
    "nx = header.get('NAXIS1')\n",
    "ny = header.get('NAXIS2')\n",
    "x_c = int(nx / 2)\n",
    "y_c = int(ny / 2)\n",
    "\n",
    "# compute RA/DEC relative shift between the edge and the center of the image\n",
    "dra, ddec = pix2coord_transform_undistorted.dot(np.array([x_c, y_c]))\n",
    "# set edge of the image such that the center has RA/DEC = (0,0)\n",
    "ra_at_xy_0, dec_at_xy_0 = -dra, -ddec\n",
    "\n",
    "# import the PixelGrid() class #\n",
    "\n",
    "deltaPix = 0.08  # size of UVIS pixel in angular coordinates #\n",
    "\n",
    "# setup the keyword arguments to create the Data() class #\n",
    "transform_pix2angle = np.array([[1, 0], [0, 1]]) * deltaPix  # linear translation matrix of a shift in pixel in a shift in coordinates\n",
    "kwargs_pixel = {'nx': nx, 'ny': ny,  # number of pixels per axis\n",
    "                'ra_at_xy_0': ra_at_xy_0,  # RA at pixel (0,0)\n",
    "                'dec_at_xy_0': dec_at_xy_0,  # DEC at pixel (0,0)\n",
    "                'transform_pix2angle': transform_pix2angle} \n",
    "pixel_grid = PixelGrid(**kwargs_pixel)\n",
    "# return the list of pixel coordinates #\n",
    "x_coords, y_coords = pixel_grid.pixel_coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f374493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display science image and obtain coordinates of point source and lens centers\n",
    "\n",
    "plt.annotate('T', [x1,y1], color='black')\n",
    "plt.annotate('T', [x2,y2], color='black')\n",
    "plt.annotate('T', [x3,y3], color='black')\n",
    "\n",
    "plt.imshow(np.log10(image_data), origin='lower', cmap='cubehelix')\n",
    "plt.show()\n",
    "\n",
    "im1 = pixel_grid.map_pix2coord(x1, y1)\n",
    "\n",
    "lens_pos = pixel_grid.map_pix2coord(x2,y2)\n",
    "\n",
    "im2 = pixel_grid.map_pix2coord(x3,y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b34d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up data class\n",
    "kwargs_data = {'image_data': image_data,\n",
    "               'background_rms': header['BACK_RMS'],\n",
    "               'exposure_time': header['EXPTIME'],\n",
    "               'ra_at_xy_0': ra_at_xy_0,  \n",
    "               'dec_at_xy_0': dec_at_xy_0,\n",
    "               'transform_pix2angle': transform_pix2angle} \n",
    "\n",
    "# lens coordinates\n",
    "lens_center_x, lens_center_y = lens_pos[0], lens_pos[1]\n",
    "# image coordinates #\n",
    "im1_x, im1_y = im1[0], im1[1]\n",
    "im2_x, im2_y = im2[0], im2[1]\n",
    "\n",
    "# calculate the initial guess for theta_E as half the image separation\n",
    "einstein_rad = np.sqrt((im2_x - im1_x)**2 + (im2_y - im1_y)**2) / 2\n",
    "print(f'Initial guess for theta_E: {einstein_rad}')\n",
    "\n",
    "# set up point source and lens positions\n",
    "theta_ra = np.array([im1_x, im2_x])\n",
    "theta_dec = np.array([im1_y, im2_y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31649668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a central mask\n",
    "\n",
    "num_pix = len(kwargs_data[\"image_data\"])\n",
    "\n",
    "r1 = r1 # arcsecond\n",
    "lens_center_ra = lens_center_x\n",
    "lens_center_dec = lens_center_y\n",
    "\n",
    "mask_outer_1 = mask_util.mask_center_2d(  # Outer mask\n",
    "    lens_center_ra + dx_outer,\n",
    "    lens_center_dec + dy_outer,\n",
    "    r1,\n",
    "    util.image2array(x_coords),\n",
    "    util.image2array(y_coords),\n",
    ")\n",
    "\n",
    "mask_1 = (1 - mask_outer_1)\n",
    "\n",
    "mask1 = mask_1\n",
    "\n",
    "if use_center_mask == True:\n",
    "    mask_ext_6 = mask_util.mask_ellipse(    # Central Mask\n",
    "        util.image2array(x_coords),\n",
    "        util.image2array(y_coords),\n",
    "        lens_center_ra + dx_center,\n",
    "        lens_center_dec + dy_center,\n",
    "        0.6,\n",
    "        0.6,\n",
    "        0,\n",
    "    )\n",
    "\n",
    "    mask_3 = (1 - mask_ext_6) \n",
    "    mask1 = mask_1  * mask_3\n",
    "\n",
    "mask1[mask1 >= 1] = 1\n",
    "\n",
    "mask1[mask1 < 0] = 0\n",
    "\n",
    "\n",
    "mask_img = mask1.reshape(num_pix, num_pix)\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15, 10))\n",
    "\n",
    "\n",
    "image = np.log10(kwargs_data[\"image_data\"] * mask_img)\n",
    "\n",
    "\n",
    "plt.sca(axs[0])\n",
    "plt.imshow(mask_img, origin=\"lower\")\n",
    "plt.title(\"MASKING\")\n",
    "\n",
    "\n",
    "plt.sca(axs[1])\n",
    "plt.imshow(image, origin=\"lower\", cmap=\"cubehelix\")\n",
    "plt.title(\"IMAGE AFTER MASKING\")\n",
    "plt.show()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e80c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model parameters\n",
    "lens_model_list = ['EPL', 'SHEAR']\n",
    "\n",
    "lens_light_model_list = ['SERSIC_ELLIPSE', 'SERSIC_ELLIPSE']\n",
    "\n",
    "source_model_list = ['SERSIC_ELLIPSE']\n",
    "\n",
    "point_source_list = ['LENSED_POSITION']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032b7e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up model arguments\n",
    "\n",
    "kwargs_model = {'lens_model_list': lens_model_list,\n",
    "                               'lens_light_model_list': lens_light_model_list,\n",
    "                               'point_source_model_list': point_source_list,\n",
    "                               #'source_light_model_list': source_model_list\n",
    "                               }\n",
    "\n",
    "kwargs_numerics = {'supersampling_factor': 1, 'supersampling_convolution': False,\n",
    "                   'point_source_supersampling_factor': 3}\n",
    "\n",
    "\n",
    "kwargs_constraints = {'num_point_source_list': [2],\n",
    "                              'joint_lens_with_light': [[0, 0, ['center_x', 'center_y']]],\n",
    "                              #'joint_source_with_point_source': [[0, 0]],\n",
    "                              'joint_lens_light_with_lens_light': [[0, 1, ['center_x', 'center_y']]]\n",
    "                              }\n",
    "\n",
    "kwargs_likelihood = {'check_bounds': True,\n",
    "                     'image_likelihood_mask_list': [mask_img],\n",
    "                      #'image_position_uncertainty': 0.004,\n",
    "                        #'check_matched_source_position': True,\n",
    "                        'source_position_likelihood': True,\n",
    "                              'source_position_tolerance': 0.001\n",
    "                              }\n",
    "\n",
    "\n",
    "image_band = [kwargs_data, kwargs_psf, kwargs_numerics]\n",
    "multi_band_list = [image_band]\n",
    "kwargs_data_joint = {'multi_band_list': multi_band_list, 'multi_band_type': 'multi-linear'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f819b3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial guess of non-linear parameters\n",
    "kwargs_lens_init = [{'theta_E': einstein_rad, 'gamma': 2., 'e1': .0, 'e2': .0, 'center_x': lens_center_x, 'center_y': lens_center_y},\n",
    "                    {'gamma1': 0., 'gamma2': 0., 'ra_0': 0, 'dec_0': 0}]\n",
    "kwargs_lens_light_init = [{'R_sersic': 2., 'n_sersic': 4., 'e1': 0., 'e2': .0, 'center_x': lens_center_x, 'center_y': lens_center_y},\n",
    "                          #{'amp': 20}]\n",
    "                          {'R_sersic': 3., 'n_sersic': 4., 'e1': 0., 'e2': .0, 'center_x': lens_center_x, 'center_y': lens_center_y}\n",
    "                          ]\n",
    "kwargs_source_init = [{'R_sersic': 0.1, 'n_sersic': 1., 'e1': 0, 'e2': 0, 'center_x': lens_center_x, 'center_y': lens_center_y}]\n",
    "kwargs_ps_init = [{'ra_image': theta_ra, 'dec_image': theta_dec}]\n",
    "\n",
    "# initial spread in parameter estimation #\n",
    "kwargs_lens_sigma = [{'theta_E': 0.2, 'gamma': .5, 'e1': .1, 'e2': .1, 'center_x': 0.1, 'center_y': 0.1},\n",
    "                     {'gamma1': 0.02, 'gamma2': 0.02, 'ra_0': 1, 'dec_0': 1}]\n",
    "kwargs_lens_light_sigma = [{'R_sersic': .5, 'n_sersic': .5, 'e1': .1, 'e2': .1, 'center_x': .1, 'center_y': 0.1},\n",
    "                           #{'amp': 10}]\n",
    "                           {'R_sersic': .5, 'n_sersic': .5, 'e1': .1, 'e2': .1, 'center_x': .1, 'center_y': 0.1}]\n",
    "kwargs_source_sigma = [{'R_sersic': .05, 'n_sersic': .5, 'e1': 0.5, 'e2': 0.5, 'center_x': .5, 'center_y': .5}]\n",
    "kwargs_ps_sigma = [{'ra_image': [0.02] * 2, 'dec_image': [0.02] * 2}]\n",
    "\n",
    "# hard bound lower limit in parameter space #\n",
    "kwargs_lower_lens = [{'theta_E': 0.01, 'gamma': 1., 'e1': -0.25, 'e2': -0.25, 'center_x': -10., 'center_y': -10},\n",
    "                     {'gamma1': -0.3, 'gamma2': -0.3, 'ra_0': -10, 'dec_0': -10}]\n",
    "kwargs_lower_lens_light = [{'R_sersic': 0.1, 'n_sersic': 0.5, 'e1': -0.25, 'e2': - 0.25, 'center_x': -10, 'center_y': -10},\n",
    "                           #{'amp': -100}]\n",
    "                           {'R_sersic': 0.1, 'n_sersic': 0.5, 'e1': -0.25, 'e2': - 0.25, 'center_x': -10, 'center_y': -10}]\n",
    "kwargs_lower_source = [{'R_sersic': 0.05, 'n_sersic': 0.5, 'e1': -0.25, 'e2': -0.25, 'center_x': -10, 'center_y': -10}]\n",
    "kwargs_lower_ps = [{'ra_image': -10 * np.ones_like(theta_ra), 'dec_image': -10 * np.ones_like(theta_dec)}]\n",
    "\n",
    "# hard bound upper limit in parameter space #\n",
    "kwargs_upper_lens = [{'theta_E': 10, 'gamma': 3., 'e1': 0.25, 'e2': 0.25, 'center_x': lens_center_x + 1, 'center_y': 10},\n",
    "                     {'gamma1': 0.3, 'gamma2': 0.3, 'ra_0': 10, 'dec_0': 10}]\n",
    "kwargs_upper_lens_light = [{'R_sersic': 10, 'n_sersic': 6., 'e1': 0.25, 'e2': 0.25, 'center_x': lens_center_x + 1, 'center_y': 10},\n",
    "                           #{'amp': 100}]\n",
    "                           {'R_sersic': 10, 'n_sersic': 6., 'e1': 0.25, 'e2': 0.25, 'center_x': lens_center_x + 1, 'center_y': 10}]\n",
    "kwargs_upper_source = [{'R_sersic': .5, 'n_sersic': 2, 'e1': 0.25, 'e2': 0.25, 'center_x': lens_center_x + 1, 'center_y': 10}]\n",
    "kwargs_upper_ps = [{'ra_image': 10 * np.ones_like(theta_ra), 'dec_image': 10 * np.ones_like(theta_dec)}]\n",
    "\n",
    "\n",
    "lens_params = [kwargs_lens_init, kwargs_lens_sigma, [{'gamma': 2}, {'ra_0': 0, 'dec_0': 0}], kwargs_lower_lens, kwargs_upper_lens]\n",
    "lens_light_params = [kwargs_lens_light_init, kwargs_lens_light_sigma, [{}, {}], kwargs_lower_lens_light, kwargs_upper_lens_light]\n",
    "source_params = [kwargs_source_init, kwargs_source_sigma, [{}], kwargs_lower_source, kwargs_upper_source]\n",
    "ps_params = [kwargs_ps_init, kwargs_ps_sigma, [{}], kwargs_lower_ps, kwargs_upper_ps]\n",
    "\n",
    "kwargs_params = {'lens_model': lens_params,\n",
    "                 #'source_model': source_params,\n",
    "                'lens_light_model': lens_light_params,\n",
    "                'point_source_model': ps_params}\n",
    "\n",
    "fitting_seq = FittingSequence(kwargs_data_joint, kwargs_model, kwargs_constraints, kwargs_likelihood, kwargs_params, verbose = False)\n",
    "\n",
    "\n",
    "fitting_kwargs_list = [['PSO', {'sigma_scale': 1., 'n_particles': 100, 'n_iterations': 100}]]\n",
    "\n",
    "chain_list = fitting_seq.fit_sequence(fitting_kwargs_list)\n",
    "kwargs_result = fitting_seq.best_fit()\n",
    "multi_band_list = fitting_seq.multi_band_list\n",
    "\n",
    "modelPlot = ModelPlot(multi_band_list, kwargs_model, kwargs_result, image_likelihood_mask_list=kwargs_likelihood[\"image_likelihood_mask_list\"], arrow_size=0.02, cmap_string=\"gist_heat\")\n",
    "f, axes = modelPlot.plot_main()\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc8437e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we run an iterative PSF reconstruction with the best fit model of the previous run\n",
    "method_PSF_iteration = 'stack' #use 'STARRED' to use the STARRED method for PSF reconstruction or 'stack' to use the standard lenstronomy stacking method\n",
    "\n",
    "kwargs_lbfgs = {'maxiter':1000}\n",
    "\n",
    "kwargs_optax1 = {'max_iterations': 500, 'min_iterations': None,\n",
    "                'init_learning_rate': 1e-2, 'schedule_learning_rate': True,\n",
    "                'progress_bar': True} \n",
    "\n",
    "if method_PSF_iteration == 'STARRED':\n",
    "    kwargs_psf_iter = { \n",
    "                    'keep_psf_error_map': True, \n",
    "                    'psf_symmetry': 1, \n",
    "                    'block_center_neighbour': 0.05,\n",
    "                    'num_iter': 3, #we run STARRED more than once, to see if the chi2 keeps improving after redoing the linear inversion with the new PSF. \n",
    "                    'psf_iter_factor': 1, #We fully update the PSF at each iteration, if the fit improves\n",
    "                    'kwargs_starred': {'verbose':True, 'lambda_scales':3, 'lambda_hf':3, #Choose regularisation parameters, lambda_scales and lambda_hf should be 2 or 3 if the noise is correctly scaled \n",
    "                                       'optim_list':['adabelief', 'adabelief'], 'kwargs_optim_list':[kwargs_optax1, kwargs_optax1],#Choose the optimisers to use, and pass the kwargs accordingly. One for the Moffat fit, one for the full PSF fit. \n",
    "                                       }, \n",
    "                    'use_starred': True, \n",
    "                    } \n",
    "\n",
    "else: \n",
    "    kwargs_psf_iter = {'stacking_method': 'median', \n",
    "                    'psf_symmetry': 4, \n",
    "                    'block_center_neighbour': 0.05,\n",
    "                    'num_iter': 500, \n",
    "                    'psf_iter_factor': 0.2,\n",
    "                    'keep_psf_variance_map': True\n",
    "                      }\n",
    "\n",
    "fitting_kwargs_list = [['psf_iteration', kwargs_psf_iter]]\n",
    "chain_list = fitting_seq.fit_sequence(fitting_kwargs_list)\n",
    "\n",
    "multi_band_list = fitting_seq.multi_band_list\n",
    "kwargs_psf_updated = multi_band_list[0][1]\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "f, axes = chain_plot.psf_iteration_compare(kwargs_psf_updated)\n",
    "display(f)\n",
    "\n",
    "modelPlot = ModelPlot(multi_band_list, kwargs_model, kwargs_result, image_likelihood_mask_list=kwargs_likelihood[\"image_likelihood_mask_list\"], arrow_size=0.02, cmap_string=\"gist_heat\")\n",
    "\n",
    "f, axes = modelPlot.plot_main()\n",
    "display(f)\n",
    "\n",
    "f, axes = modelPlot.plot_separate()\n",
    "display(f)\n",
    "\n",
    "f, axes = modelPlot.plot_subtract_from_data_all()\n",
    "display(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefee6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add source light model arguments and update\n",
    "# initial guesses to be results of previous run\n",
    "kwargs_model.update({'source_light_model_list': source_model_list})\n",
    "\n",
    "kwargs_constraints.update({'joint_source_with_point_source': [[0, 0]]})\n",
    "\n",
    "lens_params = [kwargs_result['kwargs_lens'], kwargs_lens_sigma, [{'gamma': 2}, {'ra_0': 0, 'dec_0': 0}], kwargs_lower_lens, kwargs_upper_lens]\n",
    "lens_light_params = [kwargs_result['kwargs_lens_light'], kwargs_lens_light_sigma, [{}, {}], kwargs_lower_lens_light, kwargs_upper_lens_light]\n",
    "source_params = [kwargs_source_init, kwargs_source_sigma, [{}], kwargs_lower_source, kwargs_upper_source]\n",
    "ps_params = [kwargs_result['kwargs_ps'], kwargs_ps_sigma, [{}], kwargs_lower_ps, kwargs_upper_ps]\n",
    "\n",
    "kwargs_params = {'lens_model': lens_params,\n",
    "                 'source_model': source_params,\n",
    "                'lens_light_model': lens_light_params,\n",
    "                'point_source_model': ps_params}\n",
    "\n",
    "fitting_seq = FittingSequence(kwargs_data_joint, kwargs_model, kwargs_constraints, kwargs_likelihood, kwargs_params, verbose = False)\n",
    "\n",
    "fitting_kwargs_list = [['PSO', {'sigma_scale': 1., 'n_particles': 100, 'n_iterations': 500}],\n",
    "                       ['psf_iteration', kwargs_psf_iter]]\n",
    "\n",
    "chain_list = fitting_seq.fit_sequence(fitting_kwargs_list)\n",
    "kwargs_result = fitting_seq.best_fit()\n",
    "multi_band_list = fitting_seq.multi_band_list\n",
    "\n",
    "modelPlot = ModelPlot(multi_band_list, kwargs_model, kwargs_result, image_likelihood_mask_list=kwargs_likelihood[\"image_likelihood_mask_list\"], arrow_size=0.02, cmap_string=\"gist_heat\")\n",
    "f, axes = modelPlot.plot_main()\n",
    "display(f)\n",
    "f, axes = modelPlot.plot_separate()\n",
    "display(f)\n",
    "f, axes = modelPlot.plot_subtract_from_data_all()\n",
    "display(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bd6778",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitting_kwargs_list = [['PSO', {'sigma_scale': 1., 'n_particles': 200, 'n_iterations': 500}],\n",
    "                       ['psf_iteration', kwargs_psf_iter],\n",
    "                       ['PSO', {'sigma_scale': 1., 'n_particles': 200, 'n_iterations': 500}],\n",
    "                       ['psf_iteration', kwargs_psf_iter],\n",
    "                       ['PSO', {'sigma_scale': 1., 'n_particles': 200, 'n_iterations': 500}],\n",
    "                       ['psf_iteration', kwargs_psf_iter],\n",
    "                       ['PSO', {'sigma_scale': 1., 'n_particles': 200, 'n_iterations': 500}],\n",
    "                       ['psf_iteration', kwargs_psf_iter]\n",
    "                       ]\n",
    "\n",
    "chain_list = fitting_seq.fit_sequence(fitting_kwargs_list)\n",
    "kwargs_result = fitting_seq.best_fit()\n",
    "multi_band_list = fitting_seq.multi_band_list\n",
    "\n",
    "modelPlot = ModelPlot(multi_band_list, kwargs_model, kwargs_result, image_likelihood_mask_list=kwargs_likelihood[\"image_likelihood_mask_list\"], arrow_size=0.02, cmap_string=\"gist_heat\")\n",
    "f, axes = modelPlot.plot_main()\n",
    "display(f)\n",
    "f, axes = modelPlot.plot_separate()\n",
    "display(f)\n",
    "f, axes = modelPlot.plot_subtract_from_data_all()\n",
    "display(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d5f394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the fitting again with more iterations\n",
    "fitting_kwargs_list = [\n",
    "                       ['PSO', {'sigma_scale': 1., 'n_particles': 200, 'n_iterations': 1000}],\n",
    "                       ['psf_iteration', kwargs_psf_iter],\n",
    "                       ['MCMC', {'n_burn': 500, 'n_run': 1000, 'walkerRatio': 10,'sigma_scale': .1}]\n",
    "]\n",
    "\n",
    "with suppress_stdout_stderr(f\"cutout_data/{system_name}/{filter}/mcmc_chain.txt.txt\"):\n",
    "\n",
    "    chain_list = fitting_seq.fit_sequence(fitting_kwargs_list)\n",
    "\n",
    "multi_band_list = fitting_seq.multi_band_list\n",
    "\n",
    "modelPlot = ModelPlot(multi_band_list, kwargs_model, kwargs_result, image_likelihood_mask_list=kwargs_likelihood[\"image_likelihood_mask_list\"], arrow_size=0.02, cmap_string=\"gist_heat\")\n",
    "f, axes = modelPlot.plot_main()\n",
    "display(f)\n",
    "\n",
    "f, axes = modelPlot.plot_separate()\n",
    "display(f)\n",
    "\n",
    "f, axes = modelPlot.plot_subtract_from_data_all()\n",
    "display(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57600836",
   "metadata": {},
   "outputs": [],
   "source": [
    "import corner\n",
    "# analyze the PSO and MCMC chain\n",
    "for i in range(len(chain_list)):\n",
    "    plot_chain = chain_plot.plot_chain_list(chain_list, i)\n",
    "plot_chain\n",
    "\n",
    "sampler_type, samples_mcmc, param_mcmc, dist_mcmc  = chain_list[1]\n",
    "\n",
    "print(\"number of non-linear parameters in the MCMC process: \", len(param_mcmc))\n",
    "print(\"parameters in order: \", param_mcmc)\n",
    "print(\"number of evaluations in the MCMC process: \", np.shape(samples_mcmc)[0])\n",
    "\n",
    "if samples_mcmc.size != 0:\n",
    "    n, num_param = np.shape(samples_mcmc)\n",
    "    plot = corner.corner(samples_mcmc[:, :], labels=param_mcmc[:], show_titles=True)\n",
    "\n",
    "plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd0d629-f296-4085-9688-6fbd747aaaae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f6db2441",
   "metadata": {},
   "source": [
    "# Flux and Magnitude Calculation\n",
    "\n",
    "modified from: [https://github.com/lenstronomy/lenstronomy-tutorials/blob/main/Notebooks/Galaxies/quasar_host_galaxy_decomposition.ipynb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e585e27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the linear inversion. The kwargs will be updated afterwards\n",
    "from lenstronomy.ImSim.image_linear_solve import ImageLinearFit\n",
    "from lenstronomy.Data.imaging_data import ImageData\n",
    "from lenstronomy.ImSim.image_model import ImageModel\n",
    "from lenstronomy.LightModel.light_model import LightModel\n",
    "from lenstronomy.PointSource.point_source import PointSource\n",
    "\n",
    "data_class = ImageData(**kwargs_data)\n",
    "lightModel = LightModel(lens_light_model_list)\n",
    "pointSource = PointSource(point_source_list)\n",
    "\n",
    "imageModel = ImageModel(data_class, psf_class, lens_light_model_class=lightModel,\n",
    "                                point_source_class=pointSource, kwargs_numerics=kwargs_numerics)\n",
    "\n",
    "imageLinearFit = ImageLinearFit(data_class=data_class, psf_class=psf_class,\n",
    "                        lens_light_model_class=lightModel,\n",
    "                        point_source_class=pointSource, \n",
    "                        kwargs_numerics=kwargs_numerics)\n",
    "lens_light_result = kwargs_result['kwargs_lens_light']\n",
    "ps_result = kwargs_result['kwargs_ps']\n",
    "image_reconstructed, _, _, _ = imageLinearFit.image_linear_solve(kwargs_lens_light=lens_light_result, kwargs_ps=ps_result)\n",
    "# flux count in point source\n",
    "image_ps = imageModel.point_source(ps_result)\n",
    "ps_flux = ps_result[0]['point_amp']\n",
    "print('Point Source Flux:', ps_flux)\n",
    "# for point sources, the fluxes in 'point_amp' are equivalent to the flux counts in the image.\n",
    "# The only difference is the smaller cutout size in the image\n",
    "\n",
    "# flux count in host galaxy\n",
    "image_host = imageModel.lens_surface_brightness(lens_light_result)\n",
    "lens_flux = np.sum(image_host)\n",
    "print('Host Galaxy Flux:', lens_flux)\n",
    "\n",
    "# to summarize\n",
    "print(\"quasar-to-host galaxy ratio: \", np.sum(image_ps)/np.sum(image_host))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01795940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot posteriors on the flux calculations\n",
    "from lenstronomy.Sampling.parameters import Param\n",
    "\n",
    "param = Param(kwargs_model, kwargs_fixed_lens=[{'gamma': 2}, {'ra_0': 0, 'dec_0': 0}],\n",
    "               kwargs_fixed_lens_light=[{}, {}], kwargs_fixed_source=[{}], kwargs_fixed_ps=[{}], **kwargs_constraints)\n",
    "\n",
    "sampler_type, samples_mcmc, param_mcmc, dist_mcmc  = chain_list[1]\n",
    "\n",
    "mcmc_new_list = []\n",
    "labels_new = [r\"Image 1 Flux\", r\"Image 2 Flux\", r\"Lens Flux\"]\n",
    "for i in range(len(samples_mcmc)):\n",
    "    # transform the parameter position of the MCMC chain in a lenstronomy convention with keyword arguments\n",
    "    kwargs_out = param.args2kwargs(samples_mcmc[i])\n",
    "    kwargs_light_lens_out = kwargs_out['kwargs_lens_light']\n",
    "    kwargs_ps_out = kwargs_out['kwargs_ps']\n",
    "    image_reconstructed, _, _, _ = imageLinearFit.image_linear_solve(kwargs_lens_light=kwargs_light_lens_out, kwargs_ps=kwargs_ps_out)\n",
    "\n",
    "    image_ps = imageModel.point_source(kwargs_ps_out)\n",
    "    flux_im1 = kwargs_ps_out[0]['point_amp'][0]\n",
    "    flux_im2 = kwargs_ps_out[0]['point_amp'][1]\n",
    "\n",
    "    image_lens = imageModel.lens_surface_brightness(kwargs_light_lens_out, k=0)\n",
    "    flux_lens = np.sum(image_lens)\n",
    "\n",
    "    mcmc_new_list.append([flux_im1, flux_im2, flux_lens])\n",
    "\n",
    "plot = corner.corner(np.array(mcmc_new_list), labels=labels_new, show_titles=True)\n",
    "plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bd8c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is for easier saving of data, instead of hand-writing the sigma values from the posteriors\n",
    "mcmc_new_array = np.array(mcmc_new_list)\n",
    "\n",
    "# extract fluxes for quasar images and lens\n",
    "im1_fluxes = mcmc_new_array[:, 0]\n",
    "im2_fluxes = mcmc_new_array[:, 1]\n",
    "lens_fluxes = mcmc_new_array[:, 2]\n",
    "\n",
    "# calculate median and 1-sigma uncertainties\n",
    "def get_median_and_uncertainties(samples):\n",
    "    median = np.median(samples)\n",
    "    lower, upper = np.percentile(samples, [16, 84])\n",
    "    return median, lower, upper\n",
    "\n",
    "# get values for each component\n",
    "im1_flux_median, im1_flux_lower, im1_flux_upper = get_median_and_uncertainties(im1_fluxes)\n",
    "im2_flux_median, im2_flux_lower, im2_flux_upper = get_median_and_uncertainties(im2_fluxes)\n",
    "lens_flux_median, lens_flux_lower, lens_flux_upper = get_median_and_uncertainties(lens_fluxes)\n",
    "\n",
    "# calculate 1-sigma intervals\n",
    "im1_flux_sigma = (im1_flux_upper - im1_flux_median, im1_flux_median - im1_flux_lower)\n",
    "im2_flux_sigma = (im2_flux_upper - im2_flux_median, im2_flux_median - im2_flux_lower)\n",
    "lens_flux_sigma = (lens_flux_upper - lens_flux_median, lens_flux_median - lens_flux_lower)\n",
    "\n",
    "# display results\n",
    "print(f\"Image 1 Flux: {im1_flux_median:.2f} (+{im1_flux_sigma[0]:.2f}, -{im1_flux_sigma[1]:.2f})\")\n",
    "print(f\"Image 2 Flux: {im2_flux_median:.2f} (+{im2_flux_sigma[0]:.2f}, -{im2_flux_sigma[1]:.2f})\")\n",
    "print(f\"Lens Flux: {lens_flux_median:.2f} (+{lens_flux_sigma[0]:.2f}, -{lens_flux_sigma[1]:.2f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4debb45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prep for magnitude calculations\n",
    "def prep_phot_pars_array():\n",
    "        \n",
    "    filename = f'cutout_data/{system_name}/{filter}/{system_name}_{filter}_cutout.fits'\n",
    "\n",
    "    with fits.open(filename) as hdul:\n",
    "        header = hdul[0].header\n",
    "    \n",
    "    photzpt =  header['photzpt']\n",
    "    photflam = header['photflam']\n",
    "    photplam = header['photplam']\n",
    "    \n",
    "    return [photflam, photzpt, photplam]\n",
    "\n",
    "def get_stmag(electron_flux):\n",
    "   \n",
    "   photflam, photzpt, photplam = prep_phot_pars_array()\n",
    "   \n",
    "   flux = np.asarray(electron_flux)\n",
    "   scalar_input = False\n",
    "   if flux.ndim == 0:\n",
    "      flux = flux[None]  \n",
    "      scalar_input = True\n",
    "\n",
    "   flux = flux * photflam\n",
    "   mag = -2.5 * np.log10(flux) + photzpt\n",
    "\n",
    "   if scalar_input:\n",
    "       return np.squeeze(mag)\n",
    "\n",
    "   return mag\n",
    "\n",
    "# calculate AB magnitude\n",
    "def get_abmag(electron_flux):\n",
    "   stmag = get_stmag(electron_flux)\n",
    "\n",
    "   photflam, photzpt, photplam = prep_phot_pars_array()\n",
    "\n",
    "   return stmag - 5. * np.log10(photplam) + 2.5 * np.log10(299792458e10) - 27.5\n",
    "\n",
    "\n",
    "quasar_mags = get_abmag(ps_flux)\n",
    "print(f'Quasar Image AB Magnitudes: {quasar_mags}')\n",
    "\n",
    "lens_mag = get_abmag(lens_flux)\n",
    "print(f'Lens AB Magnitude: {lens_mag}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64167558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the final products in HDF5 format\n",
    "with h5py.File(f'cutout_data/{system_name}/{filter}/{system_name}_{filter}_final.hdf5', 'w') as f:\n",
    "        f.create_dataset('image_position', data=[ps_result[0]['ra_image'], ps_result[0]['dec_image']])\n",
    "        f.create_dataset('image_fluxes', data=kwargs_ps_out[0]['point_amp'])\n",
    "        f.create_dataset('image_fluxes_sigma', data=[np.asarray(im1_flux_sigma), np.asarray(im2_flux_sigma)])\n",
    "        f.create_dataset('image_mags', data=quasar_mags)\n",
    "        for i, result in enumerate(lens_light_result):\n",
    "            for key, value in result.items():\n",
    "                f.create_dataset(f'{key}_{i}', data=value)\n",
    "\n",
    "        f.create_dataset('lens_flux', data=lens_flux)\n",
    "        f.create_dataset('lens_flux_sigma', data=np.asarray(lens_flux_sigma))\n",
    "        f.create_dataset('lens_mag', data=lens_mag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3664f691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the class data for later analysis\n",
    "import pickle\n",
    "\n",
    "save_dict = {\n",
    "    \"fitting_seq\": fitting_seq,\n",
    "    \"kwargs_result\": kwargs_result,\n",
    "    \"multi_band_list\": multi_band_list,\n",
    "    \"kwargs_model\": kwargs_model,\n",
    "    \"kwargs_params\": kwargs_params,\n",
    "    \"chain_list\": chain_list,\n",
    "    \"kwargs_constraints\": kwargs_constraints,\n",
    "    \"kwargs_likelihood\": kwargs_likelihood,\n",
    "    \"kwargs_data_joint\": kwargs_data_joint\n",
    "}\n",
    "\n",
    "with open(f\"cutout_data/{system_name}/{filter}/{system_name}_{filter}.pkl\", \"wb\") as f:\n",
    "    pickle.dump(save_dict, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
